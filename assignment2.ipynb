{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: pink; padding: 10px; font-size: 75px;\">\n",
    "TITLE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "max_lines = 1000000\n",
    "dataset = []\n",
    "with gzip.open(\"Electronics.jsonl.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= max_lines:\n",
    "            break\n",
    "        dataset.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': 3.0,\n",
       " 'title': 'Smells like gasoline! Going back!',\n",
       " 'text': 'First & most offensive: they reek of gasoline so if you are sensitive/allergic to petroleum products like I am you will want to pass on these.  Second: the phone adapter is useless as-is. Mine was not drilled far enough to be able to tighten it into place for my iPhone 12 max. It just slipped & slid all over. Stupid me putting the adapter together first without picking up the binoculars to smell them bc I wasted 15 minutes trying to figure out how to put the adapter together bc it does not come with instructions!  I had to come back here to the website which was a total pain. Third: the tripod is also useless. I would not trust the iOS to hold my $1600 phone nor even a Mattel Barbie for that matter. It’s just inefficient for the job imo.  Third: in order to try to give an honest review I did don gloves & eyewear to check the binoculars out.  They seemed average except for mine seemed to be missing about 10% of the film costing in the lower edge of one of the lenses which would have ruined every video & photograph unplanned to take so for me these are a very huge hard pass.  I expect the accessories that come with the main product to be as good or better than the product I’m buying. Otherwise I would just buy the product as a stand alone.  Sadly, I found a decent pair of binoculars last year with a much better quality phone adapter & tripod, but they had a defect too.  Guess I’m going to have to pay more.  Ugh.',\n",
       " 'images': [{'small_image_url': 'https://m.media-amazon.com/images/I/71YN+Qk3kCL._SL256_.jpg',\n",
       "   'medium_image_url': 'https://m.media-amazon.com/images/I/71YN+Qk3kCL._SL800_.jpg',\n",
       "   'large_image_url': 'https://m.media-amazon.com/images/I/71YN+Qk3kCL._SL1600_.jpg',\n",
       "   'attachment_type': 'IMAGE'}],\n",
       " 'asin': 'B083NRGZMM',\n",
       " 'parent_asin': 'B083NRGZMM',\n",
       " 'user_id': 'AFKZENTNBQ7A7V7UXW5JJI6UGRYQ',\n",
       " 'timestamp': 1658185117948,\n",
       " 'helpful_vote': 0,\n",
       " 'verified_purchase': True}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: pink; padding: 10px; font-size: 50px;\">\n",
    "Rating Prediction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AFKZENTNBQ7A7V7UXW5JJI6UGRYQ', 'B083NRGZMM', 3.0)\n"
     ]
    }
   ],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    user, item, rating = d['user_id'], d['asin'], d['rating']\n",
    "    allRatings.append((user,item,rating))\n",
    "    userRatings[user].append(rating)\n",
    "\n",
    "print(allRatings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global average rating 4.215798\n"
     ]
    }
   ],
   "source": [
    "globalAverage = sum([rating for _,_,rating in allRatings]) / len(allRatings)\n",
    "print(\"global average rating\", globalAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 100000 100000\n"
     ]
    }
   ],
   "source": [
    "train_test_split_fraction = 0.80\n",
    "valid_test_split_fraction = 0.50\n",
    "\n",
    "N = int(len(allRatings)*train_test_split_fraction)\n",
    "ratingsTrain = allRatings[:N]\n",
    "temp = allRatings[N:]\n",
    "\n",
    "N = int(len(temp)*valid_test_split_fraction)\n",
    "ratingsValid = temp[:N]\n",
    "ratingsTest = temp[N:]\n",
    "print(len(ratingsTrain),len(ratingsValid),len(ratingsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items 277965\n",
      "number of users 146645\n"
     ]
    }
   ],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "userRatings = {}\n",
    "for user,item,rating in ratingsTrain:\n",
    "    usersPerItem[item].add((user,rating))\n",
    "    itemsPerUser[user].add((item,rating))\n",
    "    userRatings[(user,item)] = rating\n",
    "\n",
    "print(\"number of items\", len(usersPerItem))\n",
    "print(\"number of users\", len(itemsPerUser))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: lightblue; padding: 10px; font-size: 30px;\">\n",
    "MODEL\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rating_predictor(iterations, ratingsTrain, alpha, regularizer):\n",
    "    beta_user = defaultdict(float)\n",
    "    beta_item = defaultdict(float)\n",
    "    N = len(ratingsTrain)\n",
    " \n",
    "    for i in range(iterations):\n",
    "        num = sum(rating - (beta_user[user] + beta_item[item]) for user, item, rating in ratingsTrain)\n",
    "        alpha = num / N\n",
    "        \n",
    "        for user in itemsPerUser:\n",
    "            num =0\n",
    "            for item,rating in itemsPerUser[user]:\n",
    "                num += rating - (alpha + beta_item[item])\n",
    "            beta_user[user] = num/(regularizer+len(itemsPerUser[user]))\n",
    "\n",
    "        \n",
    "        for item in usersPerItem:\n",
    "            num =0\n",
    "            for user,rating in usersPerItem[item]:\n",
    "                num += rating - (alpha + beta_user[user])\n",
    "            beta_item[item] = num/(regularizer+len(usersPerItem[item]))\n",
    "\n",
    "\n",
    "\n",
    "    return alpha, beta_user, beta_item\n",
    "\n",
    "\n",
    "def rating_predictor(user,item,alpha,beta_user,beta_item):\n",
    "    return alpha + beta_user[user] + beta_item[item]\n",
    "\n",
    "\n",
    "def predict(dataset,alpha,beta_user,beta_item):\n",
    "    pred = []\n",
    "    for user,item,rating in dataset:\n",
    "        pred.append(alpha + beta_user[user] + beta_item[item])\n",
    "    return pred\n",
    "\n",
    "def predictAndMSE(dataset, alpha, beta_user, beta_item):\n",
    "    error =0\n",
    "    for user,item,rating in dataset:\n",
    "        prediction = alpha + beta_item[item] + beta_user[user]\n",
    "        error += (prediction-rating)**2\n",
    "\n",
    "    return error/len(dataset)\n",
    "\n",
    "def MSE(predictions, true):\n",
    "    error =0\n",
    "    for i,rating in enumerate(true):\n",
    "        error += (predictions[i]-rating)**2\n",
    "\n",
    "    return error/len(true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta_user, beta_item = train_rating_predictor(10, ratingsTrain, globalAverage,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(ratingsValid, alpha, beta_user, beta_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6890444186295066\n"
     ]
    }
   ],
   "source": [
    "# validMSE = predictAndMSE(ratingsValid, alpha, beta_user, beta_item)\n",
    "# print(\"MSE:\",validMSE)\n",
    "\n",
    "mse = MSE(pred, [rating for _,_,rating in ratingsValid]) \n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: lightblue; padding: 10px; font-size: 30px;\">\n",
    "Hyper parameter tuning\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.6885303660478013\n",
      "2 1.6568655117504456\n",
      "5 1.6361039145978538\n",
      "10 1.6330469305530304\n",
      "15 1.6345694788625122\n",
      "20 1.6366384416015025\n",
      "best lambda value is 1 with MSE 1.6330469305530304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lamb_vals = [1,2,5,10,15,20]\n",
    "best_lamb = lamb_vals[0]\n",
    "validMSE = float(\"inf\")\n",
    "for val in lamb_vals:\n",
    "    alpha, beta_user, beta_book = train_rating_predictor(5, ratingsTrain, globalAverage, val)\n",
    "    tempMSE = predictAndMSE(ratingsValid, alpha, beta_user, beta_book)\n",
    "    print(val, tempMSE)\n",
    "    if tempMSE < validMSE:\n",
    "        validMSE = tempMSE\n",
    "        lamb = val\n",
    "\n",
    "print(f\"best lambda value is {best_lamb} with MSE {validMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: lightblue; padding: 10px; font-size: 30px;\">\n",
    "Final prediction metrics\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta_user, beta_book = train_rating_predictor(10, ratingsTrain, globalAverage, best_lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(ratingsTest, alpha, beta_user, beta_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6568548084681705\n"
     ]
    }
   ],
   "source": [
    "mse = MSE(pred, [rating for _,_,rating in ratingsTest]) \n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
